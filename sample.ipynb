{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introdution to Machine Learning - Course Project Report\n",
    "\n",
    "Group members:\n",
    "   - Grzegorz Prasek\n",
    "   - Jakub Kindracki\n",
    "   - Mykhailo Shamrai\n",
    "   - Mateusz Mikiciuk\n",
    "   - Ernest Mo≈Çczan\n",
    "\n",
    "In this report we will describe our implementation of CNN supposed to classify users allowed to the system and users not allowed (binary classification).\n",
    "\n",
    "## Table of contents:\n",
    "1. Dataset\n",
    "2. Exploratory Data Analysis\n",
    "3. Preparing audio files for generating spectrograms\n",
    "3. Generating spectrograms\n",
    "4. Classifying spectrograms for train, test and validation datasets\n",
    "5. Model\n",
    "6. Training loop\n",
    "7. [EXTRA] **interpretability** - visualizing the behavior and function of individual cnn layers and using if for data exploration\n",
    "8. [EXTRA] **uncertainty** - using monte carlo dropout to estimate classification confidence. Comparing dropout to an ensemble of CNN networks.\n",
    "9. [EXTRA] **parameter space** examining how much individual layers of the network change during training. Investigating their re-initialization robustness."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n"
   ],
   "id": "fbc121e30a2defb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1fc95cd0044d93e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset\n",
    "\n",
    "## 1.1 Introduction to the Dataset\n",
    "The project is based on the DAPS (Device and Produced Speech) dataset, which was specifically designed for speech processing and analysis research. The primary goal of this dataset is to provide high-quality speech recordings that can be utilized in applications such as speech recognition, speaker classification, and acoustic analysis.\n",
    "\n",
    "The DAPS dataset was chosen as the primary data source due to its following characteristics:\n",
    "\n",
    "- **Data Quality**: The recordings are clean and diverse, enabling precise testing of models under both laboratory and simulated conditions.\n",
    "- **Speaker Diversity**: The dataset includes recordings from 20 distinct speakers, divided into two classes:\n",
    "  - **Class 1 (Acceptable individuals)**: Includes recordings from speakers F1, F7, F8, M3, M6, and M8.\n",
    "  - **Class 0 (Unacceptable individuals)**: Includes recordings from the remaining 14 speakers.\n",
    "- **Alignment with Project Requirements**: The dataset provides recordings that can be easily transformed into spectrograms, which are essential for the CNN-based approach employed in this project.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.2 Dataset Characteristics\n",
    "Each recording in the DAPS dataset is available as a `.wav` file and exhibits the following features:\n",
    "\n",
    "- **Standard Sampling Format**: All recordings are sampled at 16 kHz, which is sufficient for most speech processing applications.\n",
    "- **Variety in Recording Lengths**: The recordings vary in duration, necessitating preprocessing to standardize the samples for comparability.\n",
    "- **Natural and Artificial Noise**: The dataset includes samples with varying levels of noise, allowing for robustness testing of the model against disturbances.\n",
    "\n",
    "Additionally, the DAPS dataset was selected due to its accessibility and clear licensing terms, which permit its legal use for educational and research purposes.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.3 Data Preparation\n",
    "To effectively utilize the DAPS dataset in the project, several key data preparation steps were undertaken:\n",
    "\n",
    "### a) Data Cleaning\n",
    "The data cleaning process aimed to remove samples that could negatively impact model performance. The following tasks were performed:\n",
    "\n",
    "- **Duplicate Elimination**: Redundant recordings were removed to prevent overrepresentation of certain samples in the training set.\n",
    "- **Silence Removal**: Segments containing silence were identified and eliminated to improve model efficiency.\n",
    "\n",
    "### b) Data Splitting\n",
    "The dataset was split into three subsets:\n",
    "\n",
    "- **Training Set**: 70% of the data, used for model training.\n",
    "- **Validation Set**: 15% of the data, used for model evaluation during training.\n",
    "- **Test Set**: 15% of the data, used for final model evaluation.\n",
    "\n",
    "The split was performed to ensure no overlap between subsets, preventing data leakage, i.e., no fragments of the same recording were included in both the training and test sets.\n",
    "\n",
    "### c) Data Augmentation\n",
    "To increase data diversity and enhance the model's robustness against noise, the following augmentation techniques were applied:\n",
    "\n",
    "- **Adding Background Noise**: Artificial noise of varying intensities was introduced to simulate real-world acoustic conditions.\n",
    "- **Pitch Shifting**: The pitch of recordings was altered to increase speaker diversity.\n",
    "- **Trimming Recordings**: Samples were cropped to a fixed length to ensure consistency across input data.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.4 Exceptional Cases in the Data\n",
    "During data analysis, certain samples were identified as particularly challenging for classification:\n",
    "\n",
    "- **Low-Volume Recordings**: Required signal amplification to enhance quality.\n",
    "- **Samples with Significant Background Noise**: These were leveraged to evaluate the model's noise resistance.\n",
    "- **Acoustically Similar Speakers**: These samples demanded special attention during model training.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.5 Challenges and Solutions\n",
    "Several challenges were encountered while working with the data, which were addressed as follows:\n",
    "\n",
    "### Class Imbalance\n",
    "- **Problem**: Class 1 was underrepresented, with only six speakers compared to 14 in Class 0.\n",
    "- **Solution**: Data augmentation techniques were used to increase the number of samples for Class 1.\n",
    "\n",
    "### Impact of Noise\n",
    "- **Problem**: High levels of noise in some recordings negatively affected classification performance.\n",
    "- **Solution**: A noise reduction process was applied to the audio files, and augmentation with various noise levels was employed to improve robustness.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.6 Conclusion\n",
    "The prepared and processed dataset provided a solid foundation for training and testing the speech recognition model. The preprocessing steps enabled the identification and resolution of potential issues, such as the heterogeneity in recording quality. The final dataset is diverse, well-balanced, and optimized for use in spectrogram-based models.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "509391be9a317db8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "46dcbaaf41406ae3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7119944d52c7f569"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Monte Carlo Dropout for Estimating Classification Confidence: Comparison with CNN Ensembles\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "In deep learning classification tasks, the confidence of a model is a critical indicator of the reliability of its predictions. Monte Carlo Dropout (MC Dropout) is an effective technique for estimating model uncertainty by leveraging dropout layers during the inference phase. This method involves multiple passes over the same input, generating probabilistic outputs. The mean and standard deviation of these outputs provide insights into the model's confidence.\n",
    "\n",
    "This section presents a detailed analysis of MC Dropout, comparing it with an ensemble of CNN models, which requires training multiple independent networks. Additionally, we explore how the number of Monte Carlo samples affects the stability and variance of predictions, using visualizations.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Experiment with Monte Carlo Dropout\n",
    "\n",
    "### 2.1 Experiment Setup\n",
    "\n",
    "- **Model**: A trained CNN model with an active dropout layer in the fully connected layer (FC1) with a dropout probability of 50% (`p=0.5`).\n",
    "- **Input Data**: Test spectrograms representing two classes.\n",
    "- **Procedure**:\n",
    "  1. Dropout was activated during the test phase (`model.train()`).\n",
    "  2. `n` predictions were performed for each sample using different numbers of Monte Carlo samples: 2, 20, and 50.\n",
    "  3. The mean and standard deviation of predictions were calculated for each class.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Python Function for Monte Carlo Dropout Predictions\n",
    "\n",
    "The following function implements MC Dropout, enabling multiple forward passes through the model to generate predictions with uncertainty estimates:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def mc_dropout_predictions(model, data_loader, num_samples, device):\n",
    "    model.train()  # Activate dropout\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, _) in enumerate(data_loader):\n",
    "            if batch_idx == 254:\n",
    "                break\n",
    "            inputs = inputs.to(device)\n",
    "            print(f\"Processing batch {batch_idx + 1}...\")  # Batch info\n",
    "\n",
    "            # Perform multiple predictions with active dropout\n",
    "            predictions = []\n",
    "            for sample_idx in range(num_samples):\n",
    "                outputs = torch.softmax(model(inputs), dim=1)\n",
    "                print(f\"Sample {sample_idx + 1}: outputs shape = {outputs.shape}\")\n",
    "                predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "            predictions = np.array(predictions)\n",
    "            print(f\"Batch {batch_idx + 1}: predictions shape = {predictions.shape}\")  # Batch results shape\n",
    "            all_predictions.append(predictions)\n",
    "\n",
    "    return all_predictions\n",
    "```\n",
    "\n",
    "This function:\n",
    "- Activates dropout layers during inference to introduce variability.\n",
    "- Processes each batch of data to generate `num_samples` predictions per sample.\n",
    "- Computes predictions as probability distributions using `torch.softmax`.\n",
    "- Logs the batch and prediction details for debugging purposes.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Results and Visualizations\n",
    "\n",
    "### 4.1 Triangular Plots (2 Monte Carlo Samples)\n",
    "\n",
    "The triangular plots below illustrate the relationship between the mean predicted probability (X-axis) and the standard deviation (Y-axis) for two classes (Class 0 and Class 1). With only 2 Monte Carlo samples, the results exhibit significant variance, resulting in triangular-shaped distributions:\n",
    "\n",
    "- **Class 0**: Variance is highest for mean probabilities near 0.5.\n",
    "- **Class 1**: Similar to Class 0, the highest uncertainty is observed around the midpoint of the probability range.\n",
    "\n",
    "![Title of Image](chapter_9/0416c84c-c4a0-4ecf-a146-3fc8217526ba.jpg)\n",
    "![Title of Image](chapter_9/55badd5f-e8c5-4226-ac4c-4ce84c1093ba.jpg)\n",
    "### 4.2 Plots for 20 Monte Carlo Samples\n",
    "\n",
    "As the number of Monte Carlo samples increases to 20, the plots become more compact:\n",
    "\n",
    "- **Class 0**: Standard deviation significantly decreases, particularly for extreme mean probabilities (close to 0 or 1).\n",
    "- **Class 1**: Results stabilize, providing better confidence estimation.\n",
    "\n",
    "![Title of Image](chapter_9/ff198697-8f3a-4ee4-8ab9-fe73633bf368.jpg)\n",
    "![Title of Image](chapter_9/1170b8d3-81f7-49c9-8349-88eeaf214fee.jpg)\n",
    "\n",
    "### 4.3 Plots for 50 Monte Carlo Samples\n",
    "\n",
    "With 50 Monte Carlo samples:\n",
    "\n",
    "- **Class 0 and Class 1**: Variance is minimized, and results become highly stable, allowing clear differentiation between confident and uncertain predictions. The shapes of the plots resemble more parabolic distributions.\n",
    "\n",
    "![Title of Image](chapter_9/5ae9ade2-5d78-461f-8018-2f9d1440a369.jpg)\n",
    "![Title of Image](chapter_9/download.jpg)\n",
    "\n",
    "### 4.4 Histograms\n",
    "\n",
    "The histograms below present the distribution of mean probabilities for both classes:\n",
    "\n",
    "- **With fewer samples (e.g., 2)**: The distributions are less concentrated, indicating greater spread in predictions.\n",
    "- **With more samples (e.g., 20, 50)**: The distributions converge near values close to 0 or 1, signifying higher confidence for most samples.\n",
    "\n",
    "![Title of Image](chapter_9/1d2ac6ee-f0a5-410b-9a60-b82e68539b95.jpg)\n",
    "![Title of Image](chapter_9/7db013c0-d410-40ae-b2a9-364aa612315b.jpg)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Comparison with CNN Ensembles\n",
    "\n",
    "### 5.1 Ensemble Setup\n",
    "\n",
    "To compare MC Dropout with ensembles, CNN models were trained, and their predictions were averaged to compute mean probabilities and variance. The results were then compared with MC Dropout at 50 samples.\n",
    "\n",
    "### 5.2 Observations\n",
    "\n",
    "1. **Computational Complexity**:\n",
    "   - MC Dropout is significantly more efficient computationally, as it requires only one trained model.\n",
    "2. **Stability of Results**:\n",
    "   - With sufficient Monte Carlo samples (e.g., 50), MC Dropout achieves results comparable to ensembles.\n",
    "3. **Practical Applicability**:\n",
    "   - MC Dropout is more practical in environments with limited computational resources.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Conclusions\n",
    "\n",
    "Monte Carlo Dropout is a practical and efficient method for estimating model confidence in classification tasks. The experiments demonstrate that increasing the number of Monte Carlo samples significantly improves the stability and precision of results. Comparisons with CNN ensembles show that MC Dropout delivers comparable performance while being far more computationally efficient. For applications requiring interpretability and uncertainty estimation, MC Dropout offers an excellent solution.\n",
    "\n",
    "---\n",
    "\n",
    "## Python Implementation for Visualizations\n"
   ],
   "id": "4278371652791061"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cdd583fd7aa965f2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
